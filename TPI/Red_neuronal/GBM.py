import pandas as pd
import numpy as np
import ast
from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold
from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.feature_selection import SelectKBest, f_regression
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostRegressor
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

class AgriculturalProductionPredictor:
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.label_encoders = {}
        self.scaler = None
        self.feature_selector = None
        self.best_model = None
        self.feature_names = None
        self.models = {
            'xgboost': None,
            'lightgbm': None,
            'catboost': None
        }
        
    def parse_array_column(self, series):
        """Convierte strings de arrays a listas num√©ricas de forma robusta"""
        def safe_eval(x):
            try:
                # Si es NaN o None
                if pd.isna(x):
                    return []
                
                # Si ya es una lista
                if isinstance(x, list):
                    return x
                
                # Si es un float o int (NaN convertido)
                if isinstance(x, (int, float)):
                    return []
                
                # Si es string, intentar parsear
                if isinstance(x, str):
                    # Limpiar string
                    x = x.strip()
                    if x in ['', 'nan', 'NaN', 'null', 'None']:
                        return []
                    return ast.literal_eval(x)
                
                return []
            except:
                return []
        return series.apply(safe_eval)
    
    def extract_array_features(self, df, array_columns):
        """Extrae caracter√≠sticas estad√≠sticas de columnas tipo array de forma robusta"""
        new_features = {}
        
        for col in array_columns:
            if col in df.columns:
                print(f"   Procesando arrays de {col}...")
                arrays = self.parse_array_column(df[col])
                
                # Funci√≥n auxiliar para aplicar operaciones de forma segura
                def safe_apply(func, default=0):
                    def safe_func(x):
                        try:
                            if isinstance(x, list) and len(x) > 0:
                                # Filtrar valores no num√©ricos
                                numeric_vals = [v for v in x if isinstance(v, (int, float)) and not pd.isna(v)]
                                if len(numeric_vals) > 0:
                                    return func(numeric_vals)
                            return default
                        except:
                            return default
                    return arrays.apply(safe_func)
                
                # Estad√≠sticas b√°sicas con manejo robusto
                new_features[f'{col}_mean'] = safe_apply(np.mean)
                new_features[f'{col}_std'] = safe_apply(np.std)
                new_features[f'{col}_min'] = safe_apply(np.min)
                new_features[f'{col}_max'] = safe_apply(np.max)
                new_features[f'{col}_median'] = safe_apply(np.median)
                
                # Caracter√≠sticas avanzadas
                new_features[f'{col}_range'] = new_features[f'{col}_max'] - new_features[f'{col}_min']
                
                # Coeficiente de variaci√≥n con divisi√≥n segura
                mean_vals = new_features[f'{col}_mean']
                std_vals = new_features[f'{col}_std']
                new_features[f'{col}_cv'] = std_vals / (mean_vals.abs() + 1e-8)
                
                # Percentiles
                new_features[f'{col}_q25'] = safe_apply(lambda x: np.percentile(x, 25) if len(x) > 0 else 0)
                new_features[f'{col}_q75'] = safe_apply(lambda x: np.percentile(x, 75) if len(x) > 0 else 0)
                
                # Tendencias (si hay suficientes datos temporales)
                def calculate_trend(arr):
                    try:
                        if isinstance(arr, list) and len(arr) >= 3:
                            # Filtrar valores num√©ricos v√°lidos
                            numeric_vals = [v for v in arr if isinstance(v, (int, float)) and not pd.isna(v)]
                            if len(numeric_vals) >= 3:
                                x = np.arange(len(numeric_vals))
                                z = np.polyfit(x, numeric_vals, 1)
                                return z[0]  # slope
                        return 0
                    except:
                        return 0
                
                new_features[f'{col}_trend'] = arrays.apply(calculate_trend)
                
                # Contar valores v√°lidos por array
                new_features[f'{col}_count'] = arrays.apply(
                    lambda x: len([v for v in x if isinstance(v, (int, float)) and not pd.isna(v)]) 
                    if isinstance(x, list) else 0
                )
                
        return pd.DataFrame(new_features)
    
    def create_interaction_features(self, df):
        """Crea caracter√≠sticas de interacci√≥n relevantes para agricultura"""
        interactions = {}
        
        # Interacciones clim√°ticas importantes
        if 'temperatura_media_C_mean' in df.columns and 'humedad_relativa_%_mean' in df.columns:
            interactions['temp_humidity_interaction'] = df['temperatura_media_C_mean'] * df['humedad_relativa_%_mean']
        
        if 'precipitacion_mm_mes_mean' in df.columns and 'temperatura_media_C_mean' in df.columns:
            interactions['precip_temp_ratio'] = df['precipitacion_mm_mes_mean'] / (df['temperatura_media_C_mean'] + 1e-8)
        
        # √çndice de estr√©s h√≠drico simplificado
        if all(col in df.columns for col in ['precipitacion_mm_mes_mean', 'temperatura_media_C_mean', 'humedad_relativa_%_mean']):
            interactions['water_stress_index'] = (df['temperatura_media_C_mean'] * (100 - df['humedad_relativa_%_mean'])) / (df['precipitacion_mm_mes_mean'] + 1e-8)
        
        # Caracter√≠sticas del suelo
        if all(col in df.columns for col in ['clay', 'silt', 'sand']):
            interactions['soil_texture_index'] = df['clay'] / (df['sand'] + 1e-8)
        
        return pd.DataFrame(interactions)
    
    def clean_data(self, df):
        """Limpia los datos eliminando filas con valores faltantes cr√≠ticos"""
        print(f"Dataset inicial: {df.shape[0]} filas")
        
        # Crear copia para no modificar el original
        df_clean = df.copy()
        
        # 1. Identificar y reportar valores faltantes
        missing_info = df_clean.isnull().sum()
        missing_columns = missing_info[missing_info > 0]
        
        if len(missing_columns) > 0:
            print("\nüìã VALORES FALTANTES ENCONTRADOS:")
            for col, count in missing_columns.items():
                percentage = (count / len(df_clean)) * 100
                print(f"   ‚Ä¢ {col}: {count} valores ({percentage:.1f}%)")
        
        # 2. Limpiar valores especiales comunes
        # Reemplazar strings que indican datos faltantes
        missing_indicators = ['SD', 'sin datos', 'Sin datos', 'SIN DATOS', 'N/A', 'n/a', 'NULL', 'null', '', ' ', 'nan', 'NaN']
        
        for col in df_clean.columns:
            if df_clean[col].dtype == 'object':
                # Para columnas de texto, reemplazar indicadores por NaN
                df_clean[col] = df_clean[col].replace(missing_indicators, np.nan)
                
                # Intentar convertir a num√©rico si es posible
                if col not in ['cultivo_nombre', 'departamento_nombre']:
                    try:
                        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
                    except:
                        pass
        
        # 3. Manejar columnas tipo array con valores faltantes
        array_columns = ['temperatura_media_C', 'humedad_relativa_%', 'velocidad_viento_m_s', 
                        'velocidad_viento_km_h', 'precipitacion_mm_mes']
        
        for col in array_columns:
            if col in df_clean.columns:
                # Marcar como NaN si el array est√° vac√≠o o malformado
                def validate_array(x):
                    try:
                        if pd.isna(x) or x in missing_indicators:
                            return np.nan
                        
                        # Si es float (NaN convertido), marcar como inv√°lido
                        if isinstance(x, (int, float)):
                            return np.nan
                            
                        if isinstance(x, str):
                            x = x.strip()
                            if x in ['', 'nan', 'NaN', 'null', 'None', '[]']:
                                return np.nan
                            parsed = ast.literal_eval(x)
                            if len(parsed) == 0:
                                return np.nan
                            return x
                        
                        # Si ya es una lista
                        if isinstance(x, list):
                            if len(x) == 0:
                                return np.nan
                            return str(x)  # Convertir de vuelta a string para procesamiento posterior
                        
                        return x
                    except:
                        return np.nan
                
                df_clean[col] = df_clean[col].apply(validate_array)
        
        # 4. Eliminar filas con valores faltantes en columnas cr√≠ticas
        critical_columns = ['produccion_tn', 'superficie_sembrada_ha', 'cultivo_nombre']
        existing_critical = [col for col in critical_columns if col in df_clean.columns]
        
        if existing_critical:
            rows_before = len(df_clean)
            df_clean = df_clean.dropna(subset=existing_critical)
            rows_after = len(df_clean)
            removed = rows_before - rows_after
            if removed > 0:
                print(f"\nüóëÔ∏è  Eliminadas {removed} filas por valores faltantes en columnas cr√≠ticas")
        
        # 5. Para otras columnas, eliminar filas donde TODAS las caracter√≠sticas importantes son NaN
        feature_columns = [col for col in df_clean.columns 
                          if col not in ['cultivo_nombre', 'departamento_nombre', 'anio']]
        
        rows_before = len(df_clean)
        # Eliminar filas donde m√°s del 50% de las caracter√≠sticas son NaN
        threshold = len(feature_columns) * 0.5
        df_clean = df_clean.dropna(thresh=len(df_clean.columns) - threshold)
        rows_after = len(df_clean)
        removed = rows_before - rows_after
        
        if removed > 0:
            print(f"üóëÔ∏è  Eliminadas {removed} filas adicionales por exceso de valores faltantes")
        
        print(f"‚úÖ Dataset limpio: {df_clean.shape[0]} filas ({((df_clean.shape[0]/df.shape[0])*100):.1f}% conservado)")
        
        # 6. Verificar que a√∫n tenemos datos suficientes
        if len(df_clean) < 100:
            raise ValueError("‚ö†Ô∏è  Muy pocos datos despu√©s de la limpieza. Revisa tu dataset original.")
        
        # 7. Rellenar valores faltantes restantes con estrategias inteligentes
        df_clean = self.impute_remaining_values(df_clean)
        
        return df_clean
    
    def impute_remaining_values(self, df):
        """Rellena valores faltantes restantes con estrategias inteligentes"""
        df_imputed = df.copy()
        
        # Para variables num√©ricas: usar mediana por cultivo/departamento
        numeric_columns = df_imputed.select_dtypes(include=[np.number]).columns
        numeric_columns = [col for col in numeric_columns if col not in ['anio']]
        
        for col in numeric_columns:
            if df_imputed[col].isnull().any():
                # Intentar rellenar por cultivo primero
                if 'cultivo_nombre' in df_imputed.columns:
                    df_imputed[col] = df_imputed.groupby('cultivo_nombre')[col].transform(
                        lambda x: x.fillna(x.median())
                    )
                
                # Si a√∫n quedan NaN, usar la mediana general
                if df_imputed[col].isnull().any():
                    median_val = df_imputed[col].median()
                    if pd.notna(median_val):
                        df_imputed[col].fillna(median_val, inplace=True)
                    else:
                        # Si no hay mediana, usar 0
                        df_imputed[col].fillna(0, inplace=True)
        
        # Para variables categ√≥ricas: usar la moda
        categorical_columns = ['cultivo_nombre', 'departamento_nombre']
        for col in categorical_columns:
            if col in df_imputed.columns and df_imputed[col].isnull().any():
                mode_val = df_imputed[col].mode()
                if len(mode_val) > 0:
                    df_imputed[col].fillna(mode_val[0], inplace=True)
                else:
                    df_imputed[col].fillna('Desconocido', inplace=True)
        
        return df_imputed
    
    def preprocess_data(self, df, is_training=True):
        """Preprocesa los datos completos"""
        # Primero limpiar los datos
        if is_training:
            df_processed = self.clean_data(df)
        else:
            df_processed = df.copy()
            # Para predicci√≥n, aplicar imputaci√≥n b√°sica sin eliminar filas
            df_processed = self.impute_remaining_values(df_processed)
        
        # Identificar columnas tipo array
        array_columns = ['temperatura_media_C', 'humedad_relativa_%', 'velocidad_viento_m_s', 
                        'velocidad_viento_km_h', 'precipitacion_mm_mes']
        
        print("üîÑ Extrayendo caracter√≠sticas de arrays clim√°ticos...")
        # Extraer caracter√≠sticas de arrays
        array_features = self.extract_array_features(df_processed, array_columns)
        df_processed = pd.concat([df_processed, array_features], axis=1)
        
        # Eliminar columnas originales tipo array
        df_processed = df_processed.drop(columns=[col for col in array_columns if col in df_processed.columns])
        
        # Crear caracter√≠sticas de interacci√≥n
        interaction_features = self.create_interaction_features(df_processed)
        df_processed = pd.concat([df_processed, interaction_features], axis=1)
        
        # Encoding de variables categ√≥ricas
        categorical_columns = ['cultivo_nombre', 'departamento_nombre']
        for col in categorical_columns:
            if col in df_processed.columns:
                if is_training:
                    self.label_encoders[col] = LabelEncoder()
                    df_processed[col] = self.label_encoders[col].fit_transform(df_processed[col].astype(str))
                else:
                    # Para predicci√≥n, manejar valores no vistos
                    df_processed[col] = df_processed[col].astype(str)
                    for val in df_processed[col].unique():
                        if val not in self.label_encoders[col].classes_:
                            # Asignar a la clase m√°s frecuente
                            df_processed[col] = df_processed[col].replace(val, self.label_encoders[col].classes_[0])
                    df_processed[col] = self.label_encoders[col].transform(df_processed[col])
        
        # Caracter√≠sticas temporales
        if 'anio' in df_processed.columns:
            df_processed['anio_normalized'] = (df_processed['anio'] - df_processed['anio'].min()) / (df_processed['anio'].max() - df_processed['anio'].min() + 1e-8)
        
        return df_processed
    
    def prepare_features(self, df, target_column='produccion_tn', is_training=True):
        """Prepara las caracter√≠sticas para el modelo"""
        df_processed = self.preprocess_data(df, is_training)
        
        if target_column in df_processed.columns:
            X = df_processed.drop(columns=[target_column])
            y = df_processed[target_column]
        else:
            X = df_processed
            y = None
        
        # Escalado robusto (mejor para datos con outliers)
        if is_training:
            self.scaler = RobustScaler()
            X_scaled = pd.DataFrame(
                self.scaler.fit_transform(X), 
                columns=X.columns, 
                index=X.index
            )
            self.feature_names = X.columns.tolist()
        else:
            X_scaled = pd.DataFrame(
                self.scaler.transform(X), 
                columns=X.columns, 
                index=X.index
            )
        
        # Selecci√≥n de caracter√≠sticas (solo en entrenamiento)
        if is_training and y is not None:
            # Seleccionar las mejores caracter√≠sticas
            k_best = min(50, len(X_scaled.columns))  # Limitar el n√∫mero de caracter√≠sticas
            self.feature_selector = SelectKBest(f_regression, k=k_best)
            X_selected = self.feature_selector.fit_transform(X_scaled, y)
            selected_features = X_scaled.columns[self.feature_selector.get_support()]
            X_final = pd.DataFrame(X_selected, columns=selected_features, index=X_scaled.index)
        elif self.feature_selector is not None:
            X_selected = self.feature_selector.transform(X_scaled)
            selected_features = X_scaled.columns[self.feature_selector.get_support()]
            X_final = pd.DataFrame(X_selected, columns=selected_features, index=X_scaled.index)
        else:
            X_final = X_scaled
        
        # Verificar que no hay NaN despu√©s del preprocesamiento
        if X_final.isnull().any().any():
            print("‚ö†Ô∏è  Advertencia: Detectados valores NaN restantes. Aplicando limpieza final...")
            X_final = X_final.fillna(0)  # √öltimo recurso: rellenar con 0
        
        return X_final, y
    
    def get_model_params(self):
        """Par√°metros optimizados para cada modelo"""
        return {
            'xgboost': {
                'n_estimators': [100, 200, 300, 500],
                'max_depth': [3, 4, 5, 6],
                'learning_rate': [0.01, 0.05, 0.1, 0.2],
                'subsample': [0.8, 0.9, 1.0],
                'colsample_bytree': [0.8, 0.9, 1.0],
                'reg_alpha': [0, 0.1, 0.5],
                'reg_lambda': [1, 1.5, 2]
            },
            'lightgbm': {
                'n_estimators': [100, 200, 300, 500],
                'max_depth': [3, 4, 5, 6],
                'learning_rate': [0.01, 0.05, 0.1, 0.2],
                'subsample': [0.8, 0.9, 1.0],
                'colsample_bytree': [0.8, 0.9, 1.0],
                'reg_alpha': [0, 0.1, 0.5],
                'reg_lambda': [1, 1.5, 2],
                'num_leaves': [31, 63, 127]
            },
            'catboost': {
                'iterations': [100, 200, 300, 500],
                'depth': [3, 4, 5, 6],
                'learning_rate': [0.01, 0.05, 0.1, 0.2],
                'l2_leaf_reg': [1, 3, 5, 7],
                'border_count': [128, 254]
            }
        }
    
    def train_models(self, X, y, cv_folds=5):
        """Entrena m√∫ltiples modelos con optimizaci√≥n de hiperpar√°metros"""
        results = {}
        
        # Configurar validaci√≥n cruzada
        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=self.random_state)
        
        # XGBoost
        print("Optimizando XGBoost...")
        xgb_model = xgb.XGBRegressor(random_state=self.random_state, n_jobs=-1)
        xgb_search = RandomizedSearchCV(
            xgb_model, 
            self.get_model_params()['xgboost'],
            n_iter=20,
            cv=cv,
            scoring='neg_mean_squared_error',
            random_state=self.random_state,
            n_jobs=-1
        )
        xgb_search.fit(X, y)
        self.models['xgboost'] = xgb_search.best_estimator_
        results['xgboost'] = -xgb_search.best_score_
        
        # LightGBM
        print("Optimizando LightGBM...")
        lgb_model = lgb.LGBMRegressor(random_state=self.random_state, n_jobs=-1, verbose=-1)
        lgb_search = RandomizedSearchCV(
            lgb_model,
            self.get_model_params()['lightgbm'],
            n_iter=20,
            cv=cv,
            scoring='neg_mean_squared_error',
            random_state=self.random_state,
            n_jobs=-1
        )
        lgb_search.fit(X, y)
        self.models['lightgbm'] = lgb_search.best_estimator_
        results['lightgbm'] = -lgb_search.best_score_
        
        # CatBoost
        print("Optimizando CatBoost...")
        cat_model = CatBoostRegressor(random_state=self.random_state, verbose=False)
        cat_search = RandomizedSearchCV(
            cat_model,
            self.get_model_params()['catboost'],
            n_iter=20,
            cv=cv,
            scoring='neg_mean_squared_error',
            random_state=self.random_state,
            n_jobs=-1
        )
        cat_search.fit(X, y)
        self.models['catboost'] = cat_search.best_estimator_
        results['catboost'] = -cat_search.best_score_
        
        # Seleccionar el mejor modelo
        best_model_name = min(results.keys(), key=lambda k: results[k])
        self.best_model = self.models[best_model_name]
        
        print(f"\nResultados de validaci√≥n cruzada (RMSE):")
        for model_name, score in results.items():
            print(f"{model_name}: {np.sqrt(score):.2f}")
        print(f"\nMejor modelo: {best_model_name}")
        
        return results
    
    def evaluate_model(self, X_test, y_test):
        """Eval√∫a el mejor modelo"""
        y_pred = self.best_model.predict(X_test)
        
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        metrics = {
            'RMSE': rmse,
            'MAE': mae,
            'R¬≤': r2,
            'MSE': mse
        }
        
        return metrics, y_pred
    
    def get_feature_importance(self, top_n=20):
        """Obtiene la importancia de las caracter√≠sticas"""
        if self.best_model is None:
            return None
        
        if hasattr(self.best_model, 'feature_importances_'):
            importance = self.best_model.feature_importances_
            feature_names = self.feature_selector.get_feature_names_out() if self.feature_selector else self.feature_names
            
            importance_df = pd.DataFrame({
                'feature': feature_names,
                'importance': importance
            }).sort_values('importance', ascending=False).head(top_n)
            
            return importance_df
        
        return None
    
    def plot_model_evaluation(self, y_true, y_pred, save_plots=False):
        """
        Crea m√∫ltiples gr√°ficos para evaluar la calidad del modelo
        """
        if plt is None:
            print("Matplotlib no disponible. Instala con: pip install matplotlib seaborn")
            return
        
        # Configurar el estilo
        plt.style.use('default')
        sns.set_palette("husl")
        
        # Crear figura con subplots
        fig = plt.figure(figsize=(20, 15))
        
        # 1. Scatter plot: Predicciones vs Valores Reales
        ax1 = plt.subplot(2, 3, 1)
        plt.scatter(y_true, y_pred, alpha=0.6, s=50)
        
        # L√≠nea de predicci√≥n perfecta
        min_val = min(y_true.min(), y_pred.min())
        max_val = max(y_true.max(), y_pred.max())
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Predicci√≥n Perfecta')
        
        # L√≠nea de regresi√≥n
        z = np.polyfit(y_true, y_pred, 1)
        p = np.poly1d(z)
        plt.plot(y_true, p(y_true), "b-", alpha=0.8, label=f'Regresi√≥n (R¬≤ = {r2_score(y_true, y_pred):.3f})')
        
        plt.xlabel('Valores Reales (tn)', fontsize=12)
        plt.ylabel('Predicciones (tn)', fontsize=12)
        plt.title('Predicciones vs Valores Reales', fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2. Residuos vs Predicciones
        ax2 = plt.subplot(2, 3, 2)
        residuals = y_pred - y_true
        plt.scatter(y_pred, residuals, alpha=0.6, s=50)
        plt.axhline(y=0, color='r', linestyle='--', lw=2)
        plt.xlabel('Predicciones (tn)', fontsize=12)
        plt.ylabel('Residuos (tn)', fontsize=12)
        plt.title('Residuos vs Predicciones', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # 3. Histograma de residuos
        ax3 = plt.subplot(2, 3, 3)
        plt.hist(residuals, bins=30, alpha=0.7, density=True, color='skyblue', edgecolor='black')
        
        # Curva normal para comparaci√≥n
        mu, sigma = stats.norm.fit(residuals)
        x = np.linspace(residuals.min(), residuals.max(), 100)
        plt.plot(x, stats.norm.pdf(x, mu, sigma), 'r-', lw=2, label=f'Normal (Œº={mu:.2f}, œÉ={sigma:.2f})')
        
        plt.xlabel('Residuos (tn)', fontsize=12)
        plt.ylabel('Densidad', fontsize=12)
        plt.title('Distribuci√≥n de Residuos', fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 4. Q-Q Plot para normalidad de residuos
        ax4 = plt.subplot(2, 3, 4)
        stats.probplot(residuals, dist="norm", plot=plt)
        plt.title('Q-Q Plot de Residuos', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # 5. Errores absolutos por rango de valores
        ax5 = plt.subplot(2, 3, 5)
        abs_errors = np.abs(residuals)
        
        # Crear bins para los valores reales
        n_bins = 10
        bins = np.quantile(y_true, np.linspace(0, 1, n_bins + 1))
        bin_centers = []
        mean_errors = []
        
        for i in range(len(bins) - 1):
            mask = (y_true >= bins[i]) & (y_true < bins[i + 1])
            if mask.sum() > 0:
                bin_centers.append((bins[i] + bins[i + 1]) / 2)
                mean_errors.append(abs_errors[mask].mean())
        
        plt.plot(bin_centers, mean_errors, 'o-', linewidth=2, markersize=8)
        plt.xlabel('Valor Real (tn)', fontsize=12)
        plt.ylabel('Error Absoluto Medio (tn)', fontsize=12)
        plt.title('Error por Rango de Valores', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # 6. M√©tricas de evaluaci√≥n
        ax6 = plt.subplot(2, 3, 6)
        ax6.axis('off')
        
        # Calcular m√©tricas
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
        
        # Crear texto con m√©tricas
        metrics_text = f"""
        M√âTRICAS DE EVALUACI√ìN
        
        R¬≤ (Coef. Determinaci√≥n): {r2:.4f}
        RMSE (Error Cuadr√°tico): {rmse:.2f} tn
        MAE (Error Absoluto): {mae:.2f} tn
        MAPE (Error Porcentual): {mape:.2f}%
        
        INTERPRETACI√ìN:
        ‚Ä¢ R¬≤ = {r2:.3f} ‚Üí {"Excelente" if r2 > 0.9 else "Bueno" if r2 > 0.7 else "Regular" if r2 > 0.5 else "Pobre"} ajuste
        ‚Ä¢ RMSE = {rmse:.1f} tn ‚Üí Error t√≠pico
        ‚Ä¢ MAE = {mae:.1f} tn ‚Üí Error promedio
        
        DISTRIBUCI√ìN DE ERRORES:
        ‚Ä¢ Media residuos: {np.mean(residuals):.3f}
        ‚Ä¢ Std residuos: {np.std(residuals):.3f}
        ‚Ä¢ Residuos < 10% valor: {(np.abs(residuals/y_true) < 0.1).mean()*100:.1f}%
        """
        
        ax6.text(0.05, 0.95, metrics_text, transform=ax6.transAxes, fontsize=11,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
        
        plt.tight_layout()
        
        if save_plots:
            plt.savefig('model_evaluation.png', dpi=300, bbox_inches='tight')
            print("Gr√°ficos guardados como 'model_evaluation.png'")
        
        plt.show()
        
        # Imprimir resumen estad√≠stico
        print("\n" + "="*60)
        print("RESUMEN ESTAD√çSTICO DE LA EVALUACI√ìN")
        print("="*60)
        
        print(f"\nüìä M√âTRICAS PRINCIPALES:")
        print(f"   ‚Ä¢ R¬≤ Score: {r2:.4f} ({'Excelente' if r2 > 0.9 else 'Bueno' if r2 > 0.7 else 'Regular' if r2 > 0.5 else 'Pobre'})")
        print(f"   ‚Ä¢ RMSE: {rmse:.2f} toneladas")
        print(f"   ‚Ä¢ MAE: {mae:.2f} toneladas") 
        print(f"   ‚Ä¢ MAPE: {mape:.2f}%")
        
        print(f"\nüéØ PRECISI√ìN POR TOLERANCIA:")
        tolerances = [0.05, 0.10, 0.20, 0.30]
        for tol in tolerances:
            accurate = (np.abs(residuals / y_true) <= tol).mean() * 100
            print(f"   ‚Ä¢ Predicciones dentro del {tol*100:.0f}%: {accurate:.1f}%")
        
        print(f"\nüìà AN√ÅLISIS DE RESIDUOS:")
        print(f"   ‚Ä¢ Media de residuos: {np.mean(residuals):.3f}")
        print(f"   ‚Ä¢ Desviaci√≥n est√°ndar: {np.std(residuals):.3f}")
        print(f"   ‚Ä¢ Sesgo (skewness): {stats.skew(residuals):.3f}")
        print(f"   ‚Ä¢ Curtosis: {stats.kurtosis(residuals):.3f}")
        
        # Test de normalidad
        _, p_value = stats.shapiro(residuals[:5000] if len(residuals) > 5000 else residuals)
        print(f"   ‚Ä¢ Test normalidad (p-value): {p_value:.4f}")
        print(f"   ‚Ä¢ Residuos normales: {'S√≠' if p_value > 0.05 else 'No'}")
        
        return {
            'r2': r2,
            'rmse': rmse,
            'mae': mae,
            'mape': mape,
            'residuals_mean': np.mean(residuals),
            'residuals_std': np.std(residuals),
            'normality_p_value': p_value
        }

    def plot_feature_importance(self, top_n=15, save_plot=False):
        """Grafica la importancia de las caracter√≠sticas"""
        importance_df = self.get_feature_importance(top_n)
        
        if importance_df is None or plt is None:
            print("No se puede generar el gr√°fico de importancia")
            return
        
        plt.figure(figsize=(12, 8))
        
        # Gr√°fico de barras horizontal
        colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))
        bars = plt.barh(range(len(importance_df)), importance_df['importance'], color=colors)
        
        plt.yticks(range(len(importance_df)), importance_df['feature'])
        plt.xlabel('Importancia', fontsize=12)
        plt.title(f'Top {top_n} Caracter√≠sticas M√°s Importantes', fontsize=14, fontweight='bold')
        plt.gca().invert_yaxis()
        
        # Agregar valores en las barras
        for i, bar in enumerate(bars):
            width = bar.get_width()
            plt.text(width + 0.001, bar.get_y() + bar.get_height()/2, 
                    f'{width:.3f}', ha='left', va='center', fontsize=10)
        
        plt.grid(True, alpha=0.3, axis='x')
        plt.tight_layout()
        
        if save_plot:
            plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
            print("Gr√°fico guardado como 'feature_importance.png'")
        
        plt.show()

    def plot_learning_curves(self, X, y, save_plot=False):
        """Grafica curvas de aprendizaje para detectar overfitting"""
        if plt is None:
            print("Matplotlib no disponible")
            return
        
        print("Generando curvas de aprendizaje...")
        
        # Usar el mejor modelo encontrado
        model = self.best_model
        
        # Diferentes tama√±os de conjunto de entrenamiento
        train_sizes = np.linspace(0.1, 1.0, 10)
        train_scores = []
        val_scores = []
        
        for train_size in train_sizes:
            # Crear muestra de entrenamiento
            n_samples = int(len(X) * train_size)
            indices = np.random.choice(len(X), n_samples, replace=False)
            X_train_subset = X.iloc[indices]
            y_train_subset = y.iloc[indices]
            
            # Dividir en train/validation
            X_train_cv, X_val_cv, y_train_cv, y_val_cv = train_test_split(
                X_train_subset, y_train_subset, test_size=0.2, random_state=42
            )
            
            # Entrenar modelo
            model_copy = type(model)(**model.get_params())
            model_copy.fit(X_train_cv, y_train_cv)
            
            # Evaluar
            train_pred = model_copy.predict(X_train_cv)
            val_pred = model_copy.predict(X_val_cv)
            
            train_scores.append(r2_score(y_train_cv, train_pred))
            val_scores.append(r2_score(y_val_cv, val_pred))
        
        # Graficar
        plt.figure(figsize=(12, 8))
        
        plt.subplot(2, 1, 1)
        plt.plot(train_sizes * len(X), train_scores, 'o-', label='Score Entrenamiento', linewidth=2)
        plt.plot(train_sizes * len(X), val_scores, 'o-', label='Score Validaci√≥n', linewidth=2)
        plt.xlabel('Tama√±o Conjunto Entrenamiento')
        plt.ylabel('R¬≤ Score')
        plt.title('Curvas de Aprendizaje - R¬≤ Score', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Tambi√©n mostrar RMSE
        plt.subplot(2, 1, 2)
        train_rmse = [np.sqrt(mean_squared_error(y.iloc[np.random.choice(len(X), int(len(X) * size), replace=False)], 
                                                model.predict(X.iloc[np.random.choice(len(X), int(len(X) * size), replace=False)]))) 
                     for size in train_sizes]
        
        plt.plot(train_sizes * len(X), train_rmse, 'o-', label='RMSE', linewidth=2, color='red')
        plt.xlabel('Tama√±o Conjunto Entrenamiento')
        plt.ylabel('RMSE (toneladas)')
        plt.title('Curva de Error - RMSE', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_plot:
            plt.savefig('learning_curves.png', dpi=300, bbox_inches='tight')
        
        plt.show()

    def plot_prediction_by_crop(self, X, y_true, y_pred, save_plot=False):
        """Analiza predicciones por tipo de cultivo"""
        if plt is None:
            print("Matplotlib no disponible")
            return
        
        # Necesitamos recuperar los nombres de cultivos originales
        if 'cultivo_nombre' not in X.columns:
            print("No se puede analizar por cultivo - informaci√≥n no disponible")
            return
        
        # Decodificar nombres de cultivos
        cultivo_encoded = X['cultivo_nombre']
        if 'cultivo_nombre' in self.label_encoders:
            try:
                cultivo_nombres = self.label_encoders['cultivo_nombre'].inverse_transform(cultivo_encoded)
                
                # Crear DataFrame para an√°lisis
                df_analysis = pd.DataFrame({
                    'cultivo': cultivo_nombres,
                    'real': y_true,
                    'prediccion': y_pred,
                    'error': np.abs(y_pred - y_true)
                })
                
                # Estad√≠sticas por cultivo
                stats_by_crop = df_analysis.groupby('cultivo').agg({
                    'real': ['mean', 'std', 'count'],
                    'prediccion': ['mean', 'std'],
                    'error': ['mean', 'std']
                }).round(2)
                
                print("\nEstad√≠sticas por cultivo:")
                print(stats_by_crop)
                
                # Graficar
                fig, axes = plt.subplots(2, 2, figsize=(16, 12))
                
                # 1. Boxplot de errores por cultivo
                df_analysis.boxplot(column='error', by='cultivo', ax=axes[0,0])
                axes[0,0].set_title('Distribuci√≥n de Errores por Cultivo')
                axes[0,0].set_ylabel('Error Absoluto (tn)')
                plt.setp(axes[0,0].xaxis.get_majorticklabels(), rotation=45)
                
                # 2. Scatter por cultivo
                for i, cultivo in enumerate(df_analysis['cultivo'].unique()):
                    mask = df_analysis['cultivo'] == cultivo
                    axes[0,1].scatter(df_analysis.loc[mask, 'real'], 
                                    df_analysis.loc[mask, 'prediccion'], 
                                    label=cultivo, alpha=0.7)
                
                axes[0,1].plot([df_analysis['real'].min(), df_analysis['real'].max()], 
                              [df_analysis['real'].min(), df_analysis['real'].max()], 'r--')
                axes[0,1].set_xlabel('Valores Reales (tn)')
                axes[0,1].set_ylabel('Predicciones (tn)')
                axes[0,1].set_title('Predicciones vs Reales por Cultivo')
                axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                
                # 3. R¬≤ por cultivo
                r2_by_crop = []
                crops = []
                for cultivo in df_analysis['cultivo'].unique():
                    mask = df_analysis['cultivo'] == cultivo
                    if mask.sum() > 3:  # M√≠nimo 3 muestras
                        r2 = r2_score(df_analysis.loc[mask, 'real'], 
                                     df_analysis.loc[mask, 'prediccion'])
                        r2_by_crop.append(r2)
                        crops.append(cultivo)
                
                axes[1,0].bar(crops, r2_by_crop, alpha=0.7)
                axes[1,0].set_ylabel('R¬≤ Score')
                axes[1,0].set_title('Precisi√≥n del Modelo por Cultivo')
                plt.setp(axes[1,0].xaxis.get_majorticklabels(), rotation=45)
                axes[1,0].grid(True, alpha=0.3)
                
                # 4. Volumen de producci√≥n vs precisi√≥n
                volume_precision = df_analysis.groupby('cultivo').agg({
                    'real': 'mean',
                    'error': lambda x: r2_score(df_analysis.loc[df_analysis['cultivo'] == x.name, 'real'], 
                                               df_analysis.loc[df_analysis['cultivo'] == x.name, 'prediccion']) 
                                      if len(x) > 3 else np.nan
                }).dropna()
                
                axes[1,1].scatter(volume_precision['real'], volume_precision['error'])
                for idx, row in volume_precision.iterrows():
                    axes[1,1].annotate(idx, (row['real'], row['error']), 
                                      xytext=(5, 5), textcoords='offset points', fontsize=8)
                axes[1,1].set_xlabel('Producci√≥n Media (tn)')
                axes[1,1].set_ylabel('R¬≤ Score')
                axes[1,1].set_title('Volumen vs Precisi√≥n del Modelo')
                axes[1,1].grid(True, alpha=0.3)
                
                plt.tight_layout()
                
                if save_plot:
                    plt.savefig('prediction_by_crop.png', dpi=300, bbox_inches='tight')
                
                plt.show()
                
            except Exception as e:
                print(f"Error al decodificar cultivos: {e}")
                print("An√°lisis por cultivo no disponible")
    
    def train(self, df, target_column='produccion_tn', test_size=0.2, cv_folds=5):
        """M√©todo principal de entrenamiento"""
        print("Iniciando entrenamiento del modelo de predicci√≥n agr√≠cola...")
        print(f"Dataset inicial: {df.shape}")
        
        # Verificar si existe la columna objetivo
        if target_column not in df.columns:
            raise ValueError(f"Columna objetivo '{target_column}' no encontrada en el dataset")
        
        # Preparar caracter√≠sticas (incluye limpieza autom√°tica)
        print("\nPreprocesando y limpiando datos...")
        try:
            X, y = self.prepare_features(df, target_column, is_training=True)
            print(f"‚úÖ Datos procesados exitosamente")
            print(f"üìä Caracter√≠sticas finales: {X.shape[1]}")
            print(f"üìà Muestras para entrenamiento: {X.shape[0]}")
        except Exception as e:
            print(f"‚ùå Error en preprocesamiento: {str(e)}")
            raise
        
        # Verificaci√≥n final de calidad de datos
        if len(X) < 50:
            raise ValueError("‚ö†Ô∏è  Muy pocos datos para entrenar (m√≠nimo 50 muestras)")
        
        if X.isnull().any().any() or y.isnull().any():
            print("‚ùå Error: A√∫n hay valores NaN despu√©s del preprocesamiento")
            print("Columnas con NaN:", X.columns[X.isnull().any()].tolist())
            raise ValueError("Datos contienen valores NaN despu√©s de limpieza")
        
        # Divisi√≥n train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state, stratify=None
        )
        
        print(f"üìä Divisi√≥n: {len(X_train)} entrenamiento, {len(X_test)} prueba")
        
        # Entrenar modelos
        print("\nEntrenando y optimizando modelos...")
        try:
            cv_results = self.train_models(X_train, y_train, cv_folds)
        except Exception as e:
            print(f"‚ùå Error en entrenamiento: {str(e)}")
            raise
        
        # Evaluaci√≥n final con gr√°ficos completos
        print("\nEvaluando modelo en conjunto de prueba...")
        try:
            final_metrics, y_pred = self.comprehensive_evaluation(X_test, y_test)
        except Exception as e:
            print(f"‚ö†Ô∏è  Error en gr√°ficos, continuando con evaluaci√≥n b√°sica: {str(e)}")
            # Fallback a evaluaci√≥n b√°sica si los gr√°ficos fallan
            final_metrics, y_pred = self.evaluate_model(X_test, y_test)
        
        print("\n" + "="*50)
        print("M√âTRICAS FINALES DEL MODELO")
        print("="*50)
        for metric, value in final_metrics.items():
            if isinstance(value, float):
                print(f"{metric}: {value:.4f}")
        
        # Importancia de caracter√≠sticas
        importance_df = self.get_feature_importance()
        if importance_df is not None:
            print(f"\nüîç TOP 10 CARACTER√çSTICAS M√ÅS IMPORTANTES:")
            print(importance_df.head(10).to_string(index=False))
        
        print(f"\n‚úÖ Entrenamiento completado exitosamente!")
        print(f"üìä Modelo final: {type(self.best_model).__name__}")
        
        return {
            'cv_results': cv_results,
            'test_metrics': final_metrics,
            'feature_importance': importance_df,
            'predictions': y_pred,
            'y_test': y_test,
            'data_quality': {
                'original_samples': len(df),
                'final_samples': len(X),
                'features_count': X.shape[1],
                'data_retention': (len(X) / len(df)) * 100
            }
        }

# Ejemplo de uso completo
def main():
    """Ejemplo completo de c√≥mo usar el predictor con visualizaciones"""
    
    # Ejemplo de uso paso a paso
    print("=== PREDICTOR DE PRODUCCI√ìN AGR√çCOLA ===\n")
    
    print("üìã PASOS PARA USAR EL MODELO:")
    print("1. Cargar datos: df = pd.read_csv('tu_archivo.csv')")
    print("2. Crear predictor: predictor = AgriculturalProductionPredictor()")
    print("3. Entrenar: results = predictor.train(df)")
    print("4. Los gr√°ficos se generan autom√°ticamente durante el entrenamiento")
    print("\nüìä GR√ÅFICOS QUE SE GENERAN:")
    print("‚Ä¢ Predicciones vs Valores Reales (scatter plot)")
    print("‚Ä¢ An√°lisis de Residuos (distribuci√≥n y patrones)")
    print("‚Ä¢ Q-Q Plot para normalidad")
    print("‚Ä¢ Errores por rango de valores")
    print("‚Ä¢ Panel completo de m√©tricas")
    print("‚Ä¢ Importancia de caracter√≠sticas")
    print("‚Ä¢ An√°lisis por tipo de cultivo")
    
    print("\nüéØ INTERPRETACI√ìN DE M√âTRICAS:")
    print("‚Ä¢ R¬≤ > 0.9: Excelente ajuste")
    print("‚Ä¢ R¬≤ > 0.7: Buen ajuste") 
    print("‚Ä¢ R¬≤ > 0.5: Ajuste regular")
    print("‚Ä¢ RMSE: Error t√≠pico en toneladas")
    print("‚Ä¢ MAE: Error absoluto promedio")
    print("‚Ä¢ MAPE: Error porcentual promedio")
    
    # Crear el predictor
    predictor = AgriculturalProductionPredictor(random_state=42)
    
    # Entrenar con datos reales
    try:
        df = pd.read_csv('produccion_agro_soilgrids_meteo_final.csv')
        print(f"\nüìÇ Archivo cargado exitosamente: {df.shape}")
        results = predictor.train(df)
        
        print("\n" + "="*60)
        print("RESUMEN DE RESULTADOS")
        print("="*60)
        
        # Mostrar m√©tricas disponibles
        print(f"üìä M√©tricas disponibles: {list(results['test_metrics'].keys())}")
        
        # Acceder a m√©tricas con nombres correctos
        metrics = results['test_metrics']
        if 'r2' in metrics:
            print(f"üìà R¬≤ Score: {metrics['r2']:.4f}")
        if 'RMSE' in metrics:
            print(f"üìà RMSE: {metrics['RMSE']:.2f} toneladas")
        if 'rmse' in metrics:
            print(f"üìà RMSE: {metrics['rmse']:.2f} toneladas")
        if 'MAE' in metrics:
            print(f"üìà MAE: {metrics['MAE']:.2f} toneladas")
        if 'mae' in metrics:
            print(f"üìà MAE: {metrics['mae']:.2f} toneladas")
        
        # Informaci√≥n de calidad de datos
        data_quality = results['data_quality']
        print(f"\nüìä CALIDAD DE DATOS:")
        print(f"   ‚Ä¢ Muestras originales: {data_quality['original_samples']:,}")
        print(f"   ‚Ä¢ Muestras finales: {data_quality['final_samples']:,}")
        print(f"   ‚Ä¢ Caracter√≠sticas: {data_quality['features_count']}")
        print(f"   ‚Ä¢ Retenci√≥n de datos: {data_quality['data_retention']:.1f}%")
        
        # Interpretaci√≥n del modelo
        r2_value = None
        for key in ['r2', 'R¬≤']:
            if key in metrics:
                r2_value = metrics[key]
                break
        
        if r2_value is not None:
            if r2_value > 0.9:
                quality = "üü¢ EXCELENTE"
            elif r2_value > 0.7:
                quality = "üü° BUENO"
            elif r2_value > 0.5:
                quality = "üü† REGULAR"
            else:
                quality = "üî¥ NECESITA MEJORAS"
            
            print(f"\nüéØ EVALUACI√ìN DEL MODELO: {quality}")
            print(f"   R¬≤ = {r2_value:.4f} - El modelo explica {r2_value*100:.1f}% de la varianza")
        
        print("\n‚úÖ ¬°Modelo entrenado y evaluado exitosamente!")
        
    except FileNotFoundError:
        print("\n‚ö†Ô∏è  Archivo 'produccion_agro_soilgrids_meteo_final.csv' no encontrado")
        print("Coloca el archivo CSV en el mismo directorio que el script")
        print("\n‚úÖ Modelo listo para entrenar con tus datos!")
    except Exception as e:
        print(f"\n‚ùå Error durante el entrenamiento: {str(e)}")
        print("‚úÖ Modelo listo para usar cuando tengas los datos correctos!")
    
    # Usar el modelo paso a paso:
    df = pd.read_csv('df_con_prod.csv')
    predictor = AgriculturalProductionPredictor()
    results = predictor.train(df)

    # 1. Gr√°fico de importancia de caracter√≠sticas
    predictor.plot_feature_importance(top_n=15, save_plot=True)

    # 2. Curvas de aprendizaje
    # Necesitas los datos X, y procesados, los puedes obtener as√≠:
    X, y = predictor.prepare_features(df, target_column='produccion_tn', is_training=False)
    predictor.plot_learning_curves(X, y, save_plot=True)

    # 3. An√°lisis por cultivo
    # Necesitas X, y_true, y_pred del conjunto de test
    y_test = results['y_test']
    y_pred = results['predictions']
    # Para X_test, necesitar√≠as hacer la divisi√≥n nuevamente o modificar el c√≥digo
    # Por simplicidad, usa los datos completos:
    predictor.plot_prediction_by_crop(X, y, y_pred, save_plot=True)

    # Ver todas las m√©tricas disponibles
    print("M√©tricas:", list(results['test_metrics'].keys()))

    # Acceder a m√©tricas espec√≠ficas
    metrics = results['test_metrics']
    print("R¬≤:", metrics.get('r2', metrics.get('R¬≤', 'No disponible')))
    print("RMSE:", metrics.get('rmse', metrics.get('RMSE', 'No disponible')))

    # Hacer nuevas predicciones
    #nuevos_datos = pd.read_csv('datos_nuevos.csv')
    #predicciones = predictor.predict(nuevos_datos)
    
    return predictor

if __name__ == "__main__":
    predictor = main()